import streamlit as st
import joblib
import re
import string
import nltk
from nltk.corpus import stopwords

# ğŸ“¥ Download stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# âš ï¸ Load trained model and vectorizer
model = joblib.load("hate_speech_model.pkl")
vectorizer = joblib.load("vectorizer.pkl")

# ğŸ¯ Preprocessing function
def clean_text(text):
    text = text.lower()
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'<.*?>', '', text)
    text = text.translate(str.maketrans('', '', string.punctuation))
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]
    return ' '.join(tokens)

# ğŸŒ Streamlit page setup
st.set_page_config(page_title="Hate Speech Detector", page_icon="âš ï¸")

# ğŸ§¢ Custom Title
st.markdown("""
    <style>
    .title {
        font-size:36px;
        font-weight:bold;
        color:#FF4B4B;
        text-align:center;
    }
    .subtext {
        font-size:18px;
        color:gray;
        text-align:center;
    }
    </style>
    <div class='title'>ğŸš« Hate Speech Detection App</div>
    <div class='subtext'>Built with ML â€¢ NLP â€¢ Streamlit</div>
    <hr>
""", unsafe_allow_html=True)

# ğŸ“˜ Sidebar info
st.sidebar.title("About This App")
st.sidebar.markdown("""
This app detects **hate or offensive content** using a trained ML model.

- ğŸ§  Algorithm: Logistic Regression
- âœ¨ NLP: Tfidf + Stopword Removal
- âš™ï¸ Framework: Streamlit

ğŸ‘©â€ğŸ’» Created by: *Your Name*
""")

# ğŸ’¡ Example inputs
examples = {
    "Example 1: Positive": "I love everyone",
    "Example 2: Offensive": "You're an idiot",
    "Example 3: Aggressive": "They deserve to die",
    "Example 4: Kind": "You are amazing",
    "Example 5: Neutral": "Let's go for a walk",
}

selected = st.selectbox("ğŸ’¡ Try a sample input:", list(examples.keys()))
text_input = st.text_area("ğŸ“ Or type your own text below:", value=examples[selected])

# ğŸ§  Predict
if st.button("Detect"):
    cleaned = clean_text(text_input)
    vect = vectorizer.transform([cleaned])
    prob = model.predict_proba(vect)[0][1]

    # ğŸ¯ Show result
    if prob > 0.5:
        st.error("âš ï¸ Hate or Offensive Speech Detected")
    else:
        st.success("âœ… This text is safe.")

    # ğŸ“Š Show confidence
    st.progress(min(prob, 1.0))
    st.write(f"ğŸ§  Confidence: {round(prob * 100, 2)}%")

# ğŸ”¬ Expandable Model Info
with st.expander("ğŸ”¬ See Model Details"):
    st.markdown("""
    - **Model:** Logistic Regression (balanced)
    - **Vectorizer:** TfidfVectorizer
    - **Text Cleaning:** Lowercase, stopwords, punctuation removal
    - **Dataset:** 10-line sample dataset
    """)

# ğŸ“¬ Feedback input
st.text_input("ğŸ’¬ Want to share feedback or suggestions?")
